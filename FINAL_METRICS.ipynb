{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5M0S0LUAZu0"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtiuqHoYAbJ2"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpRroxxriIPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0749e338-b141-4e1a-9f73-c3af0b6b20a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.48.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Activation, LeakyReLU, BatchNormalization, LSTM, Bidirectional, Input, Concatenate\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import initializers\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww8sJsm_EGlU"
      },
      "source": [
        "CONCATENO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxf5Bm0qzLR4"
      },
      "outputs": [],
      "source": [
        "# caricare a mano solo file options, no underlying\n",
        "df = []\n",
        "for file in os.listdir('/'):\n",
        "  if file.endswith('csv'):\n",
        "    print('Loading file {0}...'.format(file))\n",
        "    df.append(pd.read_csv(os.path.join('/', file), sep = ';'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9fM7DLQ-GPi"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(df, axis = 0)\n",
        "# df.to_csv('options.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywuwo5afWfYu"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['Expiry_Date','Exercise_Style','Implied_Volatility']) # non tolgo Sigma60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4QPGBlzE10g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc3a212-e87c-4f24-cd02-961a0c501964"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218863, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = df.dropna(axis=0)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GQWGBu_z4uM"
      },
      "outputs": [],
      "source": [
        "call_df = df[df.Flag == 'Call'].drop(['Flag'], axis=1)\n",
        "put_df = df[df.Flag == 'Put'].drop(['Flag'], axis=1)\n",
        "#print(call_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgfN5j700KHL"
      },
      "outputs": [],
      "source": [
        "# solo ora caricare file underlying\n",
        "underlying = pd.read_csv('/underlying.csv',sep=';')\n",
        "print(underlying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6LeCBaWiWXm"
      },
      "outputs": [],
      "source": [
        "N_TIMESTEPS = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0Z05BtSkgOX"
      },
      "outputs": [],
      "source": [
        "padded = np.insert(underlying.Close.values, 0, np.array([np.nan] * N_TIMESTEPS))\n",
        "rolled = np.column_stack([np.roll(padded, i) for i in range(N_TIMESTEPS)])\n",
        "rolled = rolled[~np.isnan(rolled).any(axis=1)]\n",
        "rolled = np.column_stack((underlying.Date.values[N_TIMESTEPS - 1:], rolled))\n",
        "price_history = pd.DataFrame(data=rolled)\n",
        "joined = df.join(price_history.set_index(0), on='Date')\n",
        "print(joined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnAE_SBz3HNh"
      },
      "outputs": [],
      "source": [
        "call_df = joined[joined.Flag == 'Call'].drop(['Flag'], axis=1)\n",
        "put_df = joined[joined.Flag == 'Put'].drop(['Flag'], axis=1)\n",
        "call_df = call_df.drop(columns=['Date'])\n",
        "put_df = put_df.drop(columns=['Date'])\n",
        "#print(call_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "call_X_train_BS, call_X_test_BS, call_y_train_BS, call_y_test_BS = train_test_split(call_df.drop(['Bid', 'Ask'], axis=1),\n",
        "                                                                        (call_df.Bid + call_df.Ask) / 2,\n",
        "                                                                        test_size=0.01, random_state=42)\n",
        "put_X_train_BS, put_X_test_BS, put_y_train_BS, put_y_test_BS = train_test_split(put_df.drop(['Bid', 'Ask'], axis=1),\n",
        "                                                                    (put_df.Bid+ put_df.Ask) / 2,\n",
        "                                                                    test_size=0.01, random_state=42)"
      ],
      "metadata": {
        "id": "79aTjyOG8Ats"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YENeXQG6NRyE"
      },
      "outputs": [],
      "source": [
        "call_X_train, call_X_test, call_y_train, call_y_test = train_test_split(call_df.drop(['Bid', 'Ask','Sigma60'], axis=1), #qua drop Sigma60-> anche non necessario perché non altera i risultati\n",
        "                                                                        call_df[['Bid','Ask']],\n",
        "                                                                        test_size=0.01, random_state=42)\n",
        "put_X_train, put_X_test, put_y_train, put_y_test = train_test_split(put_df.drop(['Bid', 'Ask','Sigma60'], axis=1),\n",
        "                                                                    put_df[['Bid','Ask']],\n",
        "                                                                    test_size=0.01, random_state=42)\n",
        "#print(call_X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZti6uMl3N87"
      },
      "outputs": [],
      "source": [
        "call_X_train = call_X_train.values\n",
        "call_X_test = call_X_test.values\n",
        "put_X_train = put_X_train.values\n",
        "put_X_test = put_X_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Muk1UKvJ3P5E"
      },
      "outputs": [],
      "source": [
        "call_X_train = [call_X_train[:, -N_TIMESTEPS:].reshape(call_X_train.shape[0], N_TIMESTEPS, 1), call_X_train[:, :4]]\n",
        "call_X_test = [call_X_test[:, -N_TIMESTEPS:].reshape(call_X_test.shape[0], N_TIMESTEPS, 1), call_X_test[:, :4]]\n",
        "put_X_train = [put_X_train[:, -N_TIMESTEPS:].reshape(put_X_train.shape[0], N_TIMESTEPS, 1), put_X_train[:, :4]]\n",
        "put_X_test = [put_X_test[:, -N_TIMESTEPS:].reshape(put_X_test.shape[0], N_TIMESTEPS, 1), put_X_test[:, :4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCWoq7hn3SPz"
      },
      "outputs": [],
      "source": [
        "layers = 4 \n",
        "features = 4 \n",
        "n_batch = 128 \n",
        "n_epochs = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PIEMhoc3Bh2"
      },
      "source": [
        "METRICS QUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pgn7tMv3Ecu"
      },
      "outputs": [],
      "source": [
        "call_model = load_model('/20221003-call-lstm-v2.h5')\n",
        "put_model = load_model('/20221003-put-lstm-v2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz-KKb8t3xKw"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "def black_scholes(row):\n",
        "    S = row.Underlying_Price\n",
        "    X = row.Strike_Price\n",
        "    T = row.Maturity / 365\n",
        "    r = row.Rf_Rate / 100\n",
        "    σ = row.Sigma60\n",
        "    d1 = (np.log(S / X) + (r + (σ ** 2) / 2) * T) / (σ * (T ** .5))\n",
        "    d2 = d1 - σ * (T ** .5)\n",
        "    C = S * norm.cdf(d1) - X * np.exp(-r * T) * norm.cdf(d2)\n",
        "    return C\n",
        "def black_scholes_put(row):\n",
        "    S = row.Underlying_Price\n",
        "    X = row.Strike_Price\n",
        "    T = row.Maturity / 365\n",
        "    r = row.Rf_Rate / 100\n",
        "    σ = row.Sigma60\n",
        "    d1 = (np.log(S / X) + (r + (σ ** 2) / 2) * T) / (σ * (T ** .5))\n",
        "    d2 = d1 - σ * (T ** .5)\n",
        "    P  = norm.cdf(-d2) * X * np.exp(-r * T) - S * norm.cdf(-d1)\n",
        "    return P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPkg7NjW34fi"
      },
      "outputs": [],
      "source": [
        "def error_metrics(actual, predicted):\n",
        "    diff = actual - predicted\n",
        "    mse = np.mean(np.square(diff))\n",
        "    rel = diff / actual\n",
        "    mpe = 100 * np.median(rel)\n",
        "    aape = 100 * np.mean(np.abs(rel))\n",
        "    mape = 100 * np.median(np.abs(rel))\n",
        "    pe5 = 100 * sum(np.abs(rel) < 0.05) / rel.shape[0]\n",
        "    pe10 = 100 * sum(np.abs(rel) < 0.10) / rel.shape[0]\n",
        "    pe20 = 100 * sum(np.abs(rel) < 0.20) / rel.shape[0]\n",
        "    return [mse, bias, aape, mape, pe5, pe10, pe20]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "call_y_pred = call_model.predict(call_X_test)\n",
        "put_y_pred = put_model.predict(put_X_test)\n",
        "line1 = error_metrics(np.mean(call_y_test, axis=1), np.mean(call_y_pred, axis=1))\n",
        "line2 = error_metrics(np.mean(put_y_test, axis=1), np.mean(put_y_pred, axis=1))\n",
        "call_train_pred = call_model.predict(call_X_train)\n",
        "put_train_pred = put_model.predict(put_X_train)\n",
        "line1.insert(0, np.mean(np.square(np.diff(call_y_train, axis=1) - np.diff(call_train_pred, axis=1))))\n",
        "line2.insert(0, np.mean(np.square(np.diff(put_y_train, axis=1) - np.diff(put_train_pred, axis=1))))\n",
        "line3 = error_metrics(call_y_test_BS, black_scholes(call_X_test_BS))\n",
        "line4 = error_metrics(put_y_test_BS, black_scholes_put(put_X_test_BS))\n",
        "line3.insert(0, np.mean(np.square(call_y_train_BS - black_scholes(call_X_train_BS))))\n",
        "line4.insert(0, np.mean(np.square(put_y_train_BS - black_scholes_put(put_X_train_BS))))\n",
        "for line in (line1, line2, line3, line4):\n",
        "    print('& {:.2f} & {:.2f} & {:.2f}\\% & {:.2f}\\% & {:.2f}\\% & {:.2f}\\% & {:.2f}\\% & {:.2f}\\% \\\\\\\\'.format(*line))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqYKwxcg8TU4",
        "outputId": "da94999c-0e83-4bbb-9b0b-53f1f595df4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "& 720.19 & 85.79 & 1.88\\% & 35.32\\% & 5.71\\% & 46.85\\% & 58.70\\% & 65.37\\% \\\\\n",
            "& 167.69 & 61.02 & -0.40\\% & 22.89\\% & 2.69\\% & 63.30\\% & 73.40\\% & 77.28\\% \\\\\n",
            "& 6037.64 & 6549.02 & 93.98\\% & 63.59\\% & 93.98\\% & 15.93\\% & 21.67\\% & 27.96\\% \\\\\n",
            "& 3820.32 & 3824.51 & 56.02\\% & 52.51\\% & 56.02\\% & 32.82\\% & 38.50\\% & 41.93\\% \\\\\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}