{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5M0S0LUAZu0"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtiuqHoYAbJ2"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpRroxxriIPu"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Activation, LeakyReLU, BatchNormalization, LSTM, Bidirectional, Input, Concatenate\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import initializers\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww8sJsm_EGlU"
      },
      "source": [
        "CONCATENO I FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxf5Bm0qzLR4"
      },
      "outputs": [],
      "source": [
        "# caricare a mano solo file options, no underlying\n",
        "df = []\n",
        "for file in os.listdir('/'):\n",
        "  if file.endswith('csv'):\n",
        "    print('Loading file {0}...'.format(file))\n",
        "    df.append(pd.read_csv(os.path.join('/', file), sep = ';'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9fM7DLQ-GPi"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(df, axis = 0)\n",
        "df.to_csv('options.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67uSC8qcElYH"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywuwo5afWfYu"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['Expiry_Date','Exercise_Style','Implied_Volatility','Sigma60'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4QPGBlzE10g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d894a03-1cc7-457f-d353-4d841f04e19d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218863, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = df.dropna(axis=0)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GQWGBu_z4uM"
      },
      "outputs": [],
      "source": [
        "call_df = df[df.Flag == 'Call'].drop(['Flag'], axis=1)\n",
        "put_df = df[df.Flag == 'Put'].drop(['Flag'], axis=1)\n",
        "print(call_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgfN5j700KHL"
      },
      "outputs": [],
      "source": [
        "# solo ora caricare file underlying\n",
        "underlying = pd.read_csv('/underlying.csv',sep=';')\n",
        "print(underlying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6LeCBaWiWXm"
      },
      "outputs": [],
      "source": [
        "N_TIMESTEPS = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0Z05BtSkgOX"
      },
      "outputs": [],
      "source": [
        "padded = np.insert(underlying.Close.values, 0, np.array([np.nan] * N_TIMESTEPS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofMwBesjkgmV"
      },
      "outputs": [],
      "source": [
        "rolled = np.column_stack([np.roll(padded, i) for i in range(N_TIMESTEPS)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFotwdDtkr-x"
      },
      "outputs": [],
      "source": [
        "rolled = rolled[~np.isnan(rolled).any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41jh1Ar6kuLJ"
      },
      "outputs": [],
      "source": [
        "rolled = np.column_stack((underlying.Date.values[N_TIMESTEPS - 1:], rolled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPThc0OoiYTq"
      },
      "outputs": [],
      "source": [
        "price_history = pd.DataFrame(data=rolled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xDjcW4Vk3fp"
      },
      "outputs": [],
      "source": [
        "joined = df.join(price_history.set_index(0), on='Date')\n",
        "print(joined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnAE_SBz3HNh"
      },
      "outputs": [],
      "source": [
        "call_df = joined[joined.Flag == 'Call'].drop(['Flag'], axis=1)\n",
        "put_df = joined[joined.Flag == 'Put'].drop(['Flag'], axis=1)\n",
        "call_df = call_df.drop(columns=['Date'])\n",
        "put_df = put_df.drop(columns=['Date'])\n",
        "print(call_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YENeXQG6NRyE"
      },
      "outputs": [],
      "source": [
        "call_X_train, call_X_test, call_y_train, call_y_test = train_test_split(call_df.drop(['Bid', 'Ask'], axis=1), \n",
        "                                                                        call_df[['Bid','Ask']],\n",
        "                                                                        test_size=0.01, random_state=42)\n",
        "put_X_train, put_X_test, put_y_train, put_y_test = train_test_split(put_df.drop(['Bid', 'Ask'], axis=1),\n",
        "                                                                    put_df[['Bid','Ask']],\n",
        "                                                                    test_size=0.01, random_state=42)\n",
        "print(call_X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZti6uMl3N87"
      },
      "outputs": [],
      "source": [
        "call_X_train = call_X_train.values\n",
        "call_X_test = call_X_test.values\n",
        "put_X_train = put_X_train.values\n",
        "put_X_test = put_X_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Muk1UKvJ3P5E"
      },
      "outputs": [],
      "source": [
        "call_X_train = [call_X_train[:, -N_TIMESTEPS:].reshape(call_X_train.shape[0], N_TIMESTEPS, 1), call_X_train[:, :4]]\n",
        "call_X_test = [call_X_test[:, -N_TIMESTEPS:].reshape(call_X_test.shape[0], N_TIMESTEPS, 1), call_X_test[:, :4]]\n",
        "put_X_train = [put_X_train[:, -N_TIMESTEPS:].reshape(put_X_train.shape[0], N_TIMESTEPS, 1), put_X_train[:, :4]]\n",
        "put_X_test = [put_X_test[:, -N_TIMESTEPS:].reshape(put_X_test.shape[0], N_TIMESTEPS, 1), put_X_test[:, :4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCWoq7hn3SPz"
      },
      "outputs": [],
      "source": [
        "layers = 4 \n",
        "features = 4\n",
        "n_batch = 128 \n",
        "n_epochs = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfoAP6t_3UGA"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    close_history = Input((N_TIMESTEPS, 1))\n",
        "    input2 = Input((features,))\n",
        "    \n",
        "    lstm = Sequential()\n",
        "    lstm.add(LSTM(units=8, input_shape=(N_TIMESTEPS, 1), return_sequences=True))\n",
        "    lstm.add(LSTM(units=8, return_sequences=True))\n",
        "    lstm.add(LSTM(units=8, return_sequences=True))\n",
        "    lstm.add(LSTM(units=8, return_sequences=False))\n",
        "    input1 = lstm(close_history)\n",
        "    \n",
        "    connect = Concatenate()([input1, input2])\n",
        "    \n",
        "    for _ in range(layers - 1):\n",
        "        connect = Dense(400, kernel_initializer=tf.keras.initializers.GlorotNormal())(connect)\n",
        "        connect = BatchNormalization()(connect)\n",
        "        connect = LeakyReLU()(connect)\n",
        "    \n",
        "    predict = Dense(2, activation='relu')(connect)\n",
        "\n",
        "    return Model(inputs=[close_history, input2], outputs=predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlD823Fa3VsB"
      },
      "outputs": [],
      "source": [
        "call_model = make_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfOlWfWM3XoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfe9950-7e05-4089-a376-aab3a54e21f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 60, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 8)            1952        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 12)           0           ['sequential[0][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 400)          5200        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 400)         1600        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 400)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 400)          160400      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 400)         1600        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 400)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 400)          160400      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 400)         1600        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 400)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 2)            802         ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 333,554\n",
            "Trainable params: 331,154\n",
            "Non-trainable params: 2,400\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "call_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMFQVJxW3hbw",
        "outputId": "0a3e04ff-0e83-413f-f45e-57aa0caa0ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "827/827 [==============================] - 24s 17ms/step - loss: 11718.6670 - val_loss: 10042.2646\n",
            "Epoch 2/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 3069.8538 - val_loss: 2126.4910\n",
            "Epoch 3/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2994.2952 - val_loss: 4591.5747\n",
            "Epoch 4/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2963.5598 - val_loss: 506.6681\n",
            "Epoch 5/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2727.4934 - val_loss: 12287.1973\n",
            "Epoch 6/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 3151.8442 - val_loss: 8980.4824\n",
            "Epoch 7/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2569.3711 - val_loss: 358.2010\n",
            "Epoch 8/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2905.1638 - val_loss: 2748.6440\n",
            "Epoch 9/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2634.9792 - val_loss: 1476.4606\n",
            "Epoch 10/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2823.7617 - val_loss: 7948.4795\n",
            "Epoch 11/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2675.1963 - val_loss: 10735.8252\n",
            "Epoch 12/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2598.1570 - val_loss: 4766.8589\n",
            "Epoch 13/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2634.0012 - val_loss: 1390.9310\n",
            "Epoch 14/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2420.9041 - val_loss: 3319.7124\n",
            "Epoch 15/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2609.4617 - val_loss: 24612.9805\n",
            "Epoch 16/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2380.4519 - val_loss: 2435.8523\n",
            "Epoch 17/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2344.3516 - val_loss: 1813.9215\n",
            "Epoch 18/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2338.0549 - val_loss: 19736.5430\n",
            "Epoch 19/40\n",
            "827/827 [==============================] - 13s 15ms/step - loss: 2329.6492 - val_loss: 6829.3545\n",
            "Epoch 20/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2333.0046 - val_loss: 2327.9163\n",
            "Epoch 21/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2112.0327 - val_loss: 2573.1594\n",
            "Epoch 22/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2157.4700 - val_loss: 1177.4224\n",
            "Epoch 23/40\n",
            "827/827 [==============================] - 13s 16ms/step - loss: 2157.2393 - val_loss: 698.1664\n",
            "Epoch 24/40\n",
            "827/827 [==============================] - 13s 15ms/step - loss: 1960.1901 - val_loss: 770.1974\n",
            "Epoch 25/40\n",
            "827/827 [==============================] - 13s 15ms/step - loss: 1916.4832 - val_loss: 1153.2538\n",
            "Epoch 26/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 2004.3799 - val_loss: 6665.7480\n",
            "Epoch 27/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1814.0144 - val_loss: 550.7245\n",
            "Epoch 28/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1918.6721 - val_loss: 769.1172\n",
            "Epoch 29/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1875.9323 - val_loss: 818.6512\n",
            "Epoch 30/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1902.4009 - val_loss: 1134.3822\n",
            "Epoch 31/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1865.4324 - val_loss: 306.4896\n",
            "Epoch 32/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1745.0348 - val_loss: 242.6455\n",
            "Epoch 33/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1747.9874 - val_loss: 4290.0337\n",
            "Epoch 34/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1658.9790 - val_loss: 4522.7153\n",
            "Epoch 35/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1864.5470 - val_loss: 631.0975\n",
            "Epoch 36/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1700.0031 - val_loss: 506.9758\n",
            "Epoch 37/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1722.6696 - val_loss: 3289.2959\n",
            "Epoch 38/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1701.9548 - val_loss: 443.5182\n",
            "Epoch 39/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1689.5764 - val_loss: 822.7866\n",
            "Epoch 40/40\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1689.9506 - val_loss: 3049.6968\n"
          ]
        }
      ],
      "source": [
        "call_model.compile(optimizer=Adam(lr=1e-2), loss='mse')\n",
        "history = call_model.fit(call_X_train, call_y_train, \n",
        "                    batch_size=n_batch, epochs=n_epochs, \n",
        "                    validation_split = 0.01,\n",
        "                    callbacks=[TensorBoard()],\n",
        "                    verbose=1)\n",
        "call_model.save('saved-models/20221003-call-lstm-v1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7qF8aPS3lRt",
        "outputId": "461e2de2-122a-44eb-8f05-3d8cb758a86b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "827/827 [==============================] - 19s 16ms/step - loss: 1316.4855 - val_loss: 137.0657\n",
            "Epoch 2/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1404.6653 - val_loss: 431.0974\n",
            "Epoch 3/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1287.7406 - val_loss: 106.9891\n",
            "Epoch 4/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1291.8506 - val_loss: 207.0080\n",
            "Epoch 5/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1302.3651 - val_loss: 111.0294\n",
            "Epoch 6/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1337.7760 - val_loss: 117.3883\n",
            "Epoch 7/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1367.4969 - val_loss: 150.7468\n",
            "Epoch 8/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1314.4283 - val_loss: 455.5720\n",
            "Epoch 9/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1313.0155 - val_loss: 394.8969\n",
            "Epoch 10/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1275.8658 - val_loss: 194.7964\n",
            "Epoch 11/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1263.0902 - val_loss: 231.1807\n",
            "Epoch 12/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1323.5630 - val_loss: 159.9612\n",
            "Epoch 13/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1233.9207 - val_loss: 464.6193\n",
            "Epoch 14/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1260.3265 - val_loss: 99.8761\n",
            "Epoch 15/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1257.2324 - val_loss: 166.3345\n",
            "Epoch 16/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1357.2113 - val_loss: 174.2040\n",
            "Epoch 17/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1214.4407 - val_loss: 204.0027\n",
            "Epoch 18/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1265.4607 - val_loss: 360.8423\n",
            "Epoch 19/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1229.3304 - val_loss: 225.9326\n",
            "Epoch 20/20\n",
            "827/827 [==============================] - 12s 15ms/step - loss: 1209.4786 - val_loss: 104.0552\n"
          ]
        }
      ],
      "source": [
        "call_model.compile(optimizer=Adam(lr=1e-3), loss='mse')\n",
        "history = call_model.fit(call_X_train, call_y_train, \n",
        "                    batch_size=n_batch, epochs=20, # notare i 20 \n",
        "                    validation_split = 0.01,\n",
        "                    callbacks=[TensorBoard()],\n",
        "                    verbose=1)\n",
        "call_model.save('saved-models/20221003-call-lstm-v2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u15iPmwY3ncz",
        "outputId": "9e916376-634b-48d9-f3db-f0c7e7839e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "827/827 [==============================] - 20s 17ms/step - loss: 1678.7850 - val_loss: 96.6513\n",
            "Epoch 2/5\n",
            "827/827 [==============================] - 13s 16ms/step - loss: 1665.2687 - val_loss: 107.1808\n",
            "Epoch 3/5\n",
            "827/827 [==============================] - 13s 16ms/step - loss: 1589.6492 - val_loss: 129.9629\n",
            "Epoch 4/5\n",
            "827/827 [==============================] - 13s 15ms/step - loss: 1525.7357 - val_loss: 107.7833\n",
            "Epoch 5/5\n",
            "827/827 [==============================] - 13s 15ms/step - loss: 1609.1389 - val_loss: 133.2945\n"
          ]
        }
      ],
      "source": [
        "call_model.compile(optimizer=Adam(lr=1e-4), loss='mse')\n",
        "history = call_model.fit(call_X_train, call_y_train, \n",
        "                    batch_size=n_batch, epochs=5, \n",
        "                    validation_split = 0.01,\n",
        "                    callbacks=[TensorBoard()],\n",
        "                    verbose=1)\n",
        "call_model.save('saved-models/20221003-call-lstm-v3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXQxtmDD8Eat"
      },
      "outputs": [],
      "source": [
        "put_model = make_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWGOBOBV8E9j",
        "outputId": "f79bff04-fb00-4cca-87f9-6991527c6973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "849/849 [==============================] - 20s 17ms/step - loss: 14707.5986 - val_loss: 4092.4236\n",
            "Epoch 2/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 3211.3591 - val_loss: 1475.2931\n",
            "Epoch 3/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 3165.6074 - val_loss: 13015.1934\n",
            "Epoch 4/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2853.0225 - val_loss: 59380.4492\n",
            "Epoch 5/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2826.6267 - val_loss: 2412.1211\n",
            "Epoch 6/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 3115.9810 - val_loss: 8996.1250\n",
            "Epoch 7/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2881.3853 - val_loss: 50121.0039\n",
            "Epoch 8/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2871.6001 - val_loss: 4985.3730\n",
            "Epoch 9/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2551.4473 - val_loss: 6202.7329\n",
            "Epoch 10/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2560.4429 - val_loss: 4869.7676\n",
            "Epoch 11/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2622.3157 - val_loss: 5255.7637\n",
            "Epoch 12/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2524.9946 - val_loss: 8200.6006\n",
            "Epoch 13/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2321.3481 - val_loss: 5501.4834\n",
            "Epoch 14/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2247.4570 - val_loss: 5549.1479\n",
            "Epoch 15/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2250.7104 - val_loss: 1488.5236\n",
            "Epoch 16/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2262.5625 - val_loss: 15817.0908\n",
            "Epoch 17/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2016.7340 - val_loss: 8797.4199\n",
            "Epoch 18/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2376.2339 - val_loss: 14831.9727\n",
            "Epoch 19/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2051.1006 - val_loss: 6375.2803\n",
            "Epoch 20/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1979.5790 - val_loss: 2127.2415\n",
            "Epoch 21/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2097.9089 - val_loss: 3588.4033\n",
            "Epoch 22/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2127.5364 - val_loss: 2085.8252\n",
            "Epoch 23/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2050.6157 - val_loss: 6238.3647\n",
            "Epoch 24/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1978.1868 - val_loss: 3301.5012\n",
            "Epoch 25/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2092.3276 - val_loss: 12596.9082\n",
            "Epoch 26/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1926.9252 - val_loss: 1198.6771\n",
            "Epoch 27/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1917.3524 - val_loss: 860.0332\n",
            "Epoch 28/40\n",
            "849/849 [==============================] - 12s 15ms/step - loss: 1846.6116 - val_loss: 1474.9438\n",
            "Epoch 29/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 2002.9443 - val_loss: 190.4837\n",
            "Epoch 30/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1734.1654 - val_loss: 366.7829\n",
            "Epoch 31/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1818.6652 - val_loss: 6225.1870\n",
            "Epoch 32/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1809.2029 - val_loss: 2706.3137\n",
            "Epoch 33/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1850.0431 - val_loss: 268.8237\n",
            "Epoch 34/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1857.8599 - val_loss: 1545.1405\n",
            "Epoch 35/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1797.8097 - val_loss: 16977.7559\n",
            "Epoch 36/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1830.7784 - val_loss: 3616.2322\n",
            "Epoch 37/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1703.5909 - val_loss: 798.7075\n",
            "Epoch 38/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1778.7218 - val_loss: 4793.1440\n",
            "Epoch 39/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1689.5576 - val_loss: 3452.7781\n",
            "Epoch 40/40\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1755.4799 - val_loss: 326.9653\n"
          ]
        }
      ],
      "source": [
        "put_model.compile(optimizer=Adam(lr=1e-2), loss='mse')\n",
        "history = put_model.fit(put_X_train, put_y_train, \n",
        "                    batch_size=n_batch, epochs=n_epochs,\n",
        "                    validation_split = 0.01,\n",
        "                    callbacks=[TensorBoard()],\n",
        "                    verbose=1)\n",
        "put_model.save('saved-models/20221003-put-lstm-v1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQeGR5ARkRmn",
        "outputId": "da445f60-da0c-4b7f-84ce-94a5ed63b90c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "849/849 [==============================] - 19s 16ms/step - loss: 1422.8582 - val_loss: 1083.5237\n",
            "Epoch 2/20\n",
            "849/849 [==============================] - 12s 15ms/step - loss: 1478.2268 - val_loss: 413.7445\n",
            "Epoch 3/20\n",
            "849/849 [==============================] - 12s 15ms/step - loss: 1513.4573 - val_loss: 348.2049\n",
            "Epoch 4/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1252.2172 - val_loss: 198.9076\n",
            "Epoch 5/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1502.6931 - val_loss: 240.7350\n",
            "Epoch 6/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1470.5720 - val_loss: 410.0989\n",
            "Epoch 7/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1517.8636 - val_loss: 484.1372\n",
            "Epoch 8/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1385.7773 - val_loss: 89.5529\n",
            "Epoch 9/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1405.8359 - val_loss: 202.8044\n",
            "Epoch 10/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1461.2498 - val_loss: 145.8931\n",
            "Epoch 11/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1401.8864 - val_loss: 82.5675\n",
            "Epoch 12/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1385.6940 - val_loss: 285.5779\n",
            "Epoch 13/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1312.5533 - val_loss: 150.1673\n",
            "Epoch 14/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1423.5496 - val_loss: 580.8436\n",
            "Epoch 15/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1468.7025 - val_loss: 149.5360\n",
            "Epoch 16/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1471.8788 - val_loss: 315.1262\n",
            "Epoch 17/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1461.2806 - val_loss: 79.8652\n",
            "Epoch 18/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1379.6901 - val_loss: 170.9596\n",
            "Epoch 19/20\n",
            "849/849 [==============================] - 12s 15ms/step - loss: 1415.2100 - val_loss: 401.2651\n",
            "Epoch 20/20\n",
            "849/849 [==============================] - 13s 15ms/step - loss: 1442.4562 - val_loss: 80.8643\n"
          ]
        }
      ],
      "source": [
        "put_model.compile(optimizer=Adam(lr=1e-3), loss='mse')\n",
        "history = put_model.fit(put_X_train, put_y_train, \n",
        "                    batch_size=n_batch, epochs=20,\n",
        "                    validation_split = 0.01,\n",
        "                    callbacks=[TensorBoard()],\n",
        "                    verbose=1)\n",
        "put_model.save('saved-models/20221003-put-lstm-v2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('saved-models/20221003-call-lstm-v1.h5')\n",
        "files.download('saved-models/20221003-call-lstm-v2.h5')\n",
        "files.download('saved-models/20221003-put-lstm-v1.h5')\n",
        "files.download('saved-models/20221003-put-lstm-v2.h5')"
      ],
      "metadata": {
        "id": "qIcT1-30QlAc",
        "outputId": "f88db949-27f5-4cc9-c968-3709d928cae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_42288f39-dc05-4a90-8499-cddd2aa0f6e0\", \"20191207-call-lstm-v1.h5\", 4111680)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8ecd397d-59f1-4654-8ef2-d29e0cf7fdff\", \"20191207-call-lstm-v2.h5\", 4111680)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c6feba53-dbfb-4e24-a55e-c3f0f8bc2dbf\", \"20191207-put-lstm-v1.h5\", 4111760)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_64dbbc3f-1bfb-4e85-97ec-47b67a594658\", \"20191207-put-lstm-v2.h5\", 4111760)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}